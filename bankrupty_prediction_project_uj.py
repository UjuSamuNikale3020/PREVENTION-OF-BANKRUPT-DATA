# -*- coding: utf-8 -*-
"""BANKRUPTY_PREDICTION PROJECT_Mahesh.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1le8GPHnKJ6etJkrytZSbrMA-2e13HIY-

# BANKRUPTCY PREVENTATION PROJECT

# Business Objective:

● This is a classification project, since the variable to predict is binary (bankruptcy or non-bankruptcy).

● The goal here is to model the probability that a business goes bankrupt from different features.

## Details :

● The data file contains 7 features about 250 companies including the following variables:

● industrial_risk: 0=low risk, 0.5=medium risk, 1=high risk.

● management_risk: 0=low risk, 0.5=medium risk, 1=high risk.

● financial flexibility: 0=low flexibility, 0.5=medium flexibility, 1=high flexibility.

● credibility: 0=low credibility, 0.5=medium credibility, 1=high credibility.

● competitiveness: 0=low competitiveness, 0.5=medium competitiveness, 1=high 
competitiveness.

● operating_risk: 0=low risk, 0.5=medium risk, 1=high risk.

● class: bankruptcy, non-bankruptcy (target variable).

# IMPORTING REQUIRED LIBRARIES
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")     # This Would Remove Any Deprecated Warning

"""IMPORTING DATA SET"""

df = pd.read_csv("bankruptcy-prevention.csv",sep = ';', header = 0)
df.sample(10)

df = pd.DataFrame(df)

"""# BASIC EXPLORATRY DATA ANALYSIS"""

df.shape

df.head()

df.tail()

df.info()

df.isna().sum()     # missing values

df.describe()

df.groupby(' class').describe().T

df.columns

df.nunique()     # No of unique values under every column

"""# PIE PLOT"""

import matplotlib.pyplot as plt
plt.pie(df[' class'].value_counts(), labels=['non-bankruptcy','bankruptcy'],autopct="%0.2f")
plt.show()

# fig.axs = plt.plot(3,2)
#plt.style.use('dark_background')
plt.subplots_adjust(left=0.1,bottom=0.1,right=2,top=2,wspace=0.8,hspace=0.5)
plt.figure(figsize=(7,10))
plt.subplot(3,2,1)
df['industrial_risk'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.subplot(3,2,2)
df[' management_risk'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.subplot(3,2,3)
df[' financial_flexibility'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.subplot(3,2,4)
df[' credibility'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.subplot(3,2,5)
df[' competitiveness'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.subplot(3,2,6)
df[' operating_risk'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.subplot(3,2,6)
plt.show()

_, ax = plt.subplots(figsize=(10,6))
plt.title("7 features about 250 companies")
sns.violinplot(data=df)
plt.figure(figsize=(16,9))

"""## INFERANCES

**By above plot we can say that there are no outliers in this dataset**

>>NUMBER OF BANKRUPTCY','NON-BANKRUPTCY
"""

df[' class'].value_counts()

import seaborn as sns
sns.countplot(x = ' class',data = df)
plt.xlabel(' class')
plt.title(" NUMBER OF BANKRUPTCY','NON-BANKRUPTCY ")

""">>NUMBER OF INDUSTRIAL_RISK"""

df['industrial_risk'].value_counts()

import seaborn as sns
plt.figure(figsize=(7,4))
sns.countplot(x = 'industrial_risk',data = df)
plt.xlabel('industrial_risk')
plt.title(" NUMBER OF INDUSTRIAL_RISK ")

""">>NUMBER OF MANAGEMENT_RISK"""

df[' management_risk'].value_counts()

import seaborn as sns
plt.figure(figsize=(7,4))
sns.countplot(x = ' management_risk',data = df)
plt.xlabel(' management_risk')
plt.title(" NUMBER OF MANAGEMENT_RISK ")

""">>NUMBER OF FINANCIAL_FLEXIBILITY"""

df[' financial_flexibility'].value_counts()

import seaborn as sns
plt.figure(figsize=(7,4))
sns.countplot(x = ' financial_flexibility',data = df)
plt.xlabel(' financial_flexibility')
plt.title(" NUMBER OF FINANCIAL_FLEXIBILITY ")

""">>NUMBER OF CREDIBILITY"""

df[' credibility'].value_counts()

import seaborn as sns
plt.figure(figsize=(7,4))
sns.countplot(x = ' credibility',data = df)
plt.xlabel(' credibility')
plt.title(" NUMBER OF CREDIBILITY ")

""">>NUMBER OF COMPETITIVENESS"""

df[' competitiveness'].value_counts()

import seaborn as sns
plt.figure(figsize=(7,4))
sns.countplot(x = ' competitiveness',data = df)
plt.xlabel(' competitiveness')
plt.title(" NUMBER OF COMPETITIVENESS ")

""">>NUMBER OF OPERATING_RISK"""

df[' operating_risk'].value_counts()

import seaborn as sns
plt.figure(figsize=(7,4))
sns.countplot(x = ' operating_risk',data = df)
plt.xlabel(' operating_risk')
plt.title(" NUMBER OF OPERATING_RISK ")

"""# BANKRUPTCY = 0 ,NON-BANKRUPTCY = 1"""

df["class_as"] = 0

# df.loc[df['class'] == 'bankruptcy', 'class_as'] = 0

df.loc[df[" class"] == 'non-bankruptcy', 'class_as'] = 1
df.sample(10)

plt.style.use('dark_background')
sns.distplot([df['industrial_risk']])

plt.style.use('dark_background')
sns.distplot(df[' management_risk'])
sns.distplot(df['class_as'])
plt.grid('off')

"""# HISTOGARM plot for industrial_risk"""

sns.set_theme(style='white')

plt.figure(figsize=(7,4))
sns.histplot(df[df['class_as'] == 0]['industrial_risk'],color= 'black')      # bankruptcy industrial_risk
sns.histplot(df[df['class_as'] == 1]['industrial_risk'],color='orange')      # non-bankruptcy industrial_risk

"""# HISTOGARM plot for management_risk"""

plt.figure(figsize=(7,4))
sns.histplot(df[df['class_as'] == 0][' management_risk'],color= 'blue')     # bankruptcy industrial_risk
sns.histplot(df[df['class_as'] == 1][' management_risk'],color='yellow')    # non-bankruptcy industrial_risk

"""# HISTOGARM plot for financial_flexibility"""

plt.figure(figsize=(7,4))
sns.histplot(df[df['class_as'] == 0][' financial_flexibility'],color= 'green')   # bankruptcy industrial_risk
sns.histplot(df[df['class_as'] == 1][' financial_flexibility'],color='red')      # non-bankruptcy industrial_risk

"""# HISTOGARM plot for credibility"""

plt.figure(figsize=(7,4))
sns.histplot(df[df['class_as'] == 0][' credibility'],color= 'pink')    # bankruptcy industrial_risk
sns.histplot(df[df['class_as'] == 1][' credibility'],color='yellow')   # non-bankruptcy industrial_risk

"""# HISTOGARM plot for competitiveness"""

plt.figure(figsize=(7,4))
sns.histplot(df[df['class_as'] == 0][' competitiveness'],color= 'black')   # bankruptcy industrial_risk
sns.histplot(df[df['class_as'] == 1][' competitiveness'],color='blue')     # non-bankruptcy industrial_risk

"""# HISTOGARM plot for operating_risk"""

plt.figure(figsize=(7,4))
sns.histplot(df[df['class_as'] == 0][' operating_risk'],color= 'yellow')     # bankruptcy industrial_risk
sns.histplot(df[df['class_as'] == 1][' operating_risk'],color='violet')      # non-bankruptcy industrial_risk

"""# corelation"""

df.corr()

"""# HEATMAP"""

sns.heatmap(df.corr(), vmin = -1, vmax = 1, annot = True)

"""# inferences

**The correlation of each and every variable with one another is seen**
"""

sns.pairplot(df,hue = ' class')
plt.figure(figsize=(8,16))

plt.style.use('dark_background')
pd.plotting.scatter_matrix(df,figsize=(10,15))
plt.show()

df.drop(columns = ' class',axis =1,inplace = True)
df

x = df.drop(columns = 'class_as',axis =1)
y = df['class_as']

print(x)

print(y)

"""# CHECKING FOR THE DUPLICATES"""

df.duplicated().sum()

"""# DROPING THE DUPLICATES"""

df = df.drop_duplicates(keep = "first")

df.duplicated().sum()

df['class_as'].value_counts()

import seaborn as sns
sns.countplot(x = 'class_as',data = df)
plt.xlabel('class_as')
plt.title(" NUMBER OF BANKRUPTCY = 0','NON-BANKRUPTCY = 1 ")

"""# PIE PLOT After droping duplicates"""

import matplotlib.pyplot as plt
plt.pie(df['class_as'].value_counts(), labels=['1','0'],autopct="%0.2f")
plt.show()

""">> Data is imbalance

# OVER SAMPLING TECHNIQUE
"""

#!pip install imblearn
from imblearn.over_sampling import RandomOverSampler

ros=RandomOverSampler(random_state=0)

x,y=ros.fit_resample(x,y)

y.value_counts()

"""## *SMOOTHING TECHNIQUE"""

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=0)

x,y = smote.fit_resample(x,y)

y.value_counts()

sns.countplot(x = y)

"""**MODEL BUILDING**"""

from sklearn.model_selection import train_test_split 
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 30)
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix
# from sklearn.metrics import plot_confusion_matrix

def report(model):
    y_pred = model.predict(x_test)
    print('Accuracy of model is: ', accuracy_score(y_test,y_pred))
    print(classification_report(y_test,y_pred))
    print(confusion_matrix(y_test,y_pred))
#   plot_confusion_matrix(model,x_test,y_test)

"""# 1.KNN"""

from sklearn.neighbors import KNeighborsClassifier
knc=KNeighborsClassifier(n_neighbors=3)
knc.fit(x_train,y_train)

pred_knn = knc.predict(x_test)
pred_knn

report(knc)

"""# 2.SVC"""

from sklearn.svm import SVC
clf_linear = SVC(kernel='linear')
clf_linear.fit(x_train , y_train)

pred_svc = clf_linear.predict(x_test)
pred_svc

report(clf_linear)

from sklearn.svm import SVC
clf_poly = SVC(kernel='poly')
clf_poly.fit(x_train , y_train)

pred_svc = clf_poly.predict(x_test)
pred_svc

report(clf_poly)

"""# 3.NAVIE BAYES"""

from sklearn.naive_bayes import GaussianNB

from sklearn.naive_bayes import MultinomialNB

from sklearn.naive_bayes import BernoulliNB

GNB = GaussianNB()

MNB = MultinomialNB()

BNB = BernoulliNB()

GNB = GNB.fit(x_train ,y_train)

pred_gnb = GNB.predict(x_test)
pred_gnb

report(GNB)

"""## 4. RANDOM FOREST"""

from sklearn.ensemble import RandomForestClassifier

RFC = RandomForestClassifier(n_estimators=50, random_state=2)
RFC.fit(x_train,y_train)

pred_RF = RFC.predict(x_test)
pred_RF

report(RFC)

## Building the model with MultinomialNB

MNB = MNB.fit(x_train ,y_train)

pred_mnb = MNB.predict(x_test)
pred_mnb

report(MNB)

## Building the model with BernoulliNB

BNB = BNB.fit(x_train,y_train)

pred_Bnb = BNB.predict(x_test)
pred_Bnb

report(BNB)

"""# 5.DECISION TREE"""

from sklearn.tree import  DecisionTreeClassifier
from sklearn import tree

model_DT = DecisionTreeClassifier(criterion = 'entropy',max_depth=3)
model_DT.fit(x_train,y_train)

#PLot the decision tree
tree.plot_tree(model_DT);

# Predicting on test data
pred_DT = model_DT.predict(x_test)   # predicting on test data set

pd.Series(pred_DT).value_counts()    # getting the count of each category

pred_DT

report(model_DT)

"""## 6.LOGISTIC REGRESSION"""

# model fitting
from sklearn.linear_model import LogisticRegression
LR =LogisticRegression()
LR.fit(x_train,y_train)

# predicting the values
pred_LR = LR.predict(x_test)
pred_LR

report(LR)

"""## 7.ADABOOSTCLASSIFIER"""

from sklearn.ensemble import AdaBoostClassifier
ABC = AdaBoostClassifier(n_estimators=50, random_state=2)

ABC.fit(x_train,y_train)

# predicting the values

pred_AdaBoostClassifier = ABC.predict(x_test)
pred_AdaBoostClassifier

report(ABC)

"""# 8.GRADIENTBOOSTINGCLASSIFIER"""

from sklearn.ensemble import GradientBoostingClassifier
GBDT = GradientBoostingClassifier(n_estimators=50, random_state=2)

GBDT.fit(x_train,y_train)

# predicting the values

pred_GradientBoostingClassifier = GBDT.predict(x_test)
pred_GradientBoostingClassifier

report(GBDT)

"""## 9.XGBOOSTCLASSIFIER"""

from xgboost import XGBClassifier
XGB = XGBClassifier(n_estimators=50,random_state=2)

XGB.fit(x_train,y_train)

# predicting the values

pred_XGBClassifier = XGB.predict(x_test)
pred_XGBClassifier

report(XGB)

"""NOTE : From all the models we are getting 0.98% for the following models

Svc clf_poly 

DecisionTreeClassifier

AdaBoostClassifier

GradientBoostingClassifier

XGBClassifier

### SO WE CAN USE ANY OF THIS MODELS FOR DEPLOYMENT
"""

import pickle
pickle_out = open("clf_poly.pkl","wb")
pickle.dump(clf_poly, pickle_out)
pickle_out.close()

import pickle
pickle_out1 = open("model_DT.pkl","wb")
pickle.dump(model_DT, pickle_out1)
pickle_out1.close()

import pickle
pickle_out2 = open("ABC.pkl","wb")
pickle.dump(ABC, pickle_out2)
pickle_out2.close()

import pickle
pickle_out3 = open("GBDT.pkl","wb")
pickle.dump(GBDT, pickle_out3)
pickle_out3.close()

import pickle
pickle_out4 = open("XGB.pkl","wb")
pickle.dump(XGB, pickle_out4)
pickle_out4.close()

!pip install streamlit -q

!streamlit run /content/BANKRUOTCYstreamlitcodingMAHESH.py & npx localtunnel --port 8501

